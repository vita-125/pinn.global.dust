{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-29T15:24:59.875629Z",
     "start_time": "2025-07-29T15:24:59.856321Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import deepxde as dde\n",
    "import os\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import tensorflow as tf\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:25:57.425206Z",
     "start_time": "2025-07-29T15:25:56.523334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FIGURE_PATH = \"C:/Users/vitas/Desktop/LE PINN/pinn.global.dust/pinn.global.dust/Code/figures/\"\n",
    "DATA_PATH = \"C:/Users/vitas/Desktop/LE PINN/pinn.global.dust/pinn.global.dust/Data/\"\n",
    "DATA_LOAD_PATH = DATA_PATH + \"original_data/\"\n",
    "INPUT_MODEL_PATH = DATA_PATH + \"processed_data/\"\n",
    "MODEL_SAVE_PATH = DATA_PATH + \"trained_models/\"\n",
    "RESULTS_PATH = DATA_PATH + \"model_results/\"\n",
    "path_to_shapefile = \"C:/Users/vitas/Desktop/LE PINN/pinn.global.dust/pinn.global.dust/ne_110m_admin_0_countries.shp\"\n",
    "world = gpd.read_file(path_to_shapefile)"
   ],
   "id": "164e28e78a4627f9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:25:58.424543Z",
     "start_time": "2025-07-29T15:25:58.396975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"functions_training_model.py\", 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Execute the content of the .py file\n",
    "exec(content)"
   ],
   "id": "fb95a27c2f11fc5a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:26:00.826209Z",
     "start_time": "2025-07-29T15:26:00.705023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_simulated_Holocene = pd.read_csv(INPUT_MODEL_PATH + \"df_simulation_Holocene.csv\")\n",
    "\n",
    "df_global_grid = pd.read_csv(INPUT_MODEL_PATH + \"df_global_grid.csv\")\n",
    "df_wind = pd.read_csv(INPUT_MODEL_PATH + \"df_wind.csv\", usecols=['wind', 'latitude'])\n",
    "latitude_wind, mean_wind = df_wind['latitude'].values / 90, df_wind['wind'].values / df_wind['wind'].max()\n",
    "\n",
    "\n",
    "def wind_latitude(latitude):\n",
    "    interpolated = wind_tf_interp(latitude, tf.convert_to_tensor(latitude_wind), tf.convert_to_tensor(mean_wind))\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "tf_wind_latitude = tf.function(wind_latitude)\n"
   ],
   "id": "d53e13b76abf9eb9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:26:02.873304Z",
     "start_time": "2025-07-29T15:26:02.840024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def training_points(df):\n",
    "    data_observ_points = dde.data.DataSet(\n",
    "        X_train=df[['lon', 'lat']].values / 90,\n",
    "        y_train=df['log_dep_norm'].values.reshape(-1, 1),\n",
    "        X_test=df[['lon', 'lat']].values / 90,\n",
    "        y_test=df['log_dep_norm'].values.reshape(-1, 1),\n",
    "        standardize=False)\n",
    "\n",
    "    observe_u = dde.icbc.PointSetBC(data_observ_points.train_x,\n",
    "                                    df['log_dep_norm'].values.reshape(-1, 1), component=0)\n",
    "\n",
    "    return data_observ_points, observe_u\n",
    "\n",
    "\n",
    "x_min, x_max = -2.0, 2.0\n",
    "y_min, y_max = -0.89, 0.89\n",
    "\n",
    "left_corner = np.array([x_min, y_min])  # xmin, ymin – Coordinate of bottom left corner.\n",
    "right_corner = np.array([x_max, y_max])  # xmax, ymax – Coordinate of top right corner.\n",
    "geometry_rectangle = dde.geometry.geometry_2d.Rectangle(left_corner, right_corner)\n",
    "\n",
    "# Reduce the training domain to avoid pole singularities.\n",
    "df_simulated_Holocene_2 = df_simulated_Holocene[\n",
    "    (df_simulated_Holocene['lat'] >= -81) & (df_simulated_Holocene['lat'] <= 81)]\n",
    "\n"
   ],
   "id": "7fc3460f90880efc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:26:06.944094Z",
     "start_time": "2025-07-29T15:26:06.900815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def pde(x, u):\n",
    "    du_x = dde.grad.jacobian(u, x, j=0)  # du/dlambda\n",
    "    du_y = dde.grad.jacobian(u, x, j=1)  # du/dtheta\n",
    "\n",
    "    K = wind_latitude(x[:, 1:2])\n",
    "    K = tf.cast(K, tf.float32)\n",
    "\n",
    "    du_xx = dde.grad.hessian(u, x, i=0, j=0)  # d^2u/dlambda^2\n",
    "    du_yy = dde.grad.hessian(u, x, i=1, j=1)  # d^2u/dtheta^2\n",
    "\n",
    "    return (\n",
    "        (-K * du_x * (1 / tf.cos(x[:, 1:2] * np.pi / 2)) +\n",
    "         D * ((1 / (tf.cos(x[:, 1:2] * np.pi / 2) ** 2) * du_xx + du_yy - tf.tan(x[:, 1:2] * np.pi / 2) * du_y)))\n",
    "    )\n",
    "\n",
    "\n",
    "def space_boundary_north(x, on_boundary):\n",
    "    return on_boundary and np.isclose(y_max, x[1])\n",
    "\n",
    "\n",
    "def space_boundary_south(x, on_boundary):\n",
    "    return on_boundary and np.isclose(y_min, x[1])\n",
    "\n",
    "\n",
    "def periodic_boundary(x, domain):\n",
    "    return domain and (np.isclose(x[0], x_min) or np.isclose(x[0], x_max))\n",
    "\n"
   ],
   "id": "3879398a2fbb6196",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:26:09.623588Z",
     "start_time": "2025-07-29T15:26:09.602201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_metric(y_true, y_pred):\n",
    "    if y_true is None or y_pred is None:\n",
    "        return tf.constant(0.0)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def train_process(data_observ_points, observe_u, D, bc_1, bc_2, model_name):\n",
    "    # Percorso cartella per salvataggio modelli e variabili\n",
    "    save_dir = MODEL_SAVE_PATH + model_name + \"/\"\n",
    "\n",
    "    # Crea la cartella se non esiste\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    data = dde.data.PDE(\n",
    "        geometry_rectangle,\n",
    "        pde,\n",
    "        [observe_u, periodic_condition, periodic_condition_derivative, bc_1, bc_2],\n",
    "        num_domain=2592,\n",
    "        num_boundary=216,\n",
    "        anchors=data_observ_points.train_x,\n",
    "        train_distribution='uniform'\n",
    "    )\n",
    "\n",
    "    neurons = 32\n",
    "    layer = 5\n",
    "    layer_size = [2] + [neurons] * layer + [1]\n",
    "    activation = \"selu\"\n",
    "    initializer = \"Glorot normal\"\n",
    "    net = dde.maps.FNN(layer_size, activation, initializer)\n",
    "    model = dde.Model(data, net)\n",
    "    dde.optimizers.set_LBFGS_options(maxcor=50, ftol=1e-20, maxiter=1e5)\n",
    "    model.compile(\"adam\", lr=0.00001, external_trainable_variables=[D, north_mean, south_mean],\n",
    "                  loss_weights=[1, 10, 0.5, 0.5, 1, 1])\n",
    "\n",
    "    # Train and save the model\n",
    "\n",
    "    checkpointer = dde.callbacks.ModelCheckpoint(\n",
    "        f\"{MODEL_SAVE_PATH}{model_name}/{model_name}.ckpt\",\n",
    "        verbose=0, period=10000,\n",
    "    )\n",
    "\n",
    "    variable = dde.callbacks.VariableValue([D, north_mean, south_mean], period=10000,\n",
    "                                           filename=MODEL_SAVE_PATH + model_name + \"/variables.dat\")\n",
    "\n",
    "    losshistory, train_state = model.train(epochs=1000, callbacks=[variable, checkpointer])\n",
    "    dde.saveplot(losshistory, train_state, issave=False, isplot=True)\n",
    "    params = variable.get_value()\n",
    "\n",
    "    return model, params, train_state.best_step\n"
   ],
   "id": "c1ee3531e776d2b3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:26:14.408286Z",
     "start_time": "2025-07-29T15:26:14.307184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "north_mean = dde.Variable(-1.0)\n",
    "south_mean = dde.Variable(-2.0)\n",
    "D = dde.Variable(1.0)\n",
    "\n",
    "bc_1 = dde.DirichletBC(geometry_rectangle, lambda x: north_mean, space_boundary_north)\n",
    "bc_2 = dde.DirichletBC(geometry_rectangle, lambda x: south_mean, space_boundary_south)\n",
    "periodic_condition = dde.icbc.PeriodicBC(geom=geometry_rectangle, component_x=0, on_boundary=periodic_boundary,\n",
    "                                         derivative_order=0)\n",
    "periodic_condition_derivative = dde.icbc.PeriodicBC(geom=geometry_rectangle, component_x=0,\n",
    "                                                    on_boundary=periodic_boundary, derivative_order=1)\n"
   ],
   "id": "28f5f92f5dbfd0d6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T15:27:15.399707Z",
     "start_time": "2025-07-29T15:27:12.022664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Numero di bande\n",
    "num_bands = 18\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Numero di strisce in cui dividere la regione\n",
    "n_strisce = 18\n",
    "\n",
    "# Estremi latitudinali della regione\n",
    "lat_min, lat_max = -90,90\n",
    "lon_min, lon_max = -180 ,180\n",
    "# Calcolo gli estremi delle strisce (n_strisce+1 punti di divisione)\n",
    "lon_bands = np.linspace(lon_min, lon_max, n_strisce + 1)\n",
    "\n",
    "print(\"Limiti delle strisce longitudinali:\", lon_bands)\n",
    "\n",
    "\n",
    "bands = np.arange(num_bands)\n",
    "\n",
    "# Imposta la cross-validation a 5 fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "mse_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(bands):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "\n",
    "    train_bands = bands[train_index]\n",
    "    test_bands = bands[test_index]\n",
    "\n",
    "    # Seleziona i punti corrispondenti alle bande\n",
    "    df_train = df_simulated_Holocene_2[df_simulated_Holocene_2['lon_band'].isin(train_bands)]\n",
    "    df_test = df_simulated_Holocene_2[df_simulated_Holocene_2['lon_band'].isin(test_bands)]\n",
    "\n",
    "    print(f\"Train bands: {train_bands}\")\n",
    "    print(f\"Test bands: {test_bands}\")\n",
    "    print(f\"Punti train: {len(df_train)}, test: {len(df_test)}\")\n",
    "\n",
    "    # Training\n",
    "    data_obs, bc_point = training_points(df_train)\n",
    "    pinn_model, _, _, _ = train_process(data_obs, bc_point, D, bc_1, bc_2, f'model_fold_{fold}')\n",
    "\n",
    "    # Valutazione\n",
    "    Xg = (df_test[['lon', 'lat']].values / 90.0).astype(np.float32)\n",
    "    Yg = df_test['log_dep_norm'].values.reshape(-1, 1).astype(np.float32)\n",
    "    pinn_g = pinn_model.predict(Xg)\n",
    "    mse = np.mean((pinn_g - Yg) ** 2)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "    print(f\"MSE Fold {fold}: {mse:.4f}\")\n",
    "    fold += 1\n"
   ],
   "id": "785301021dcd9c68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiti delle strisce longitudinali: [-180. -160. -140. -120. -100.  -80.  -60.  -40.  -20.    0.   20.   40.\n",
      "   60.   80.  100.  120.  140.  160.  180.]\n",
      "\n",
      "--- Fold 1 ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lon_band'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3811\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mpandas/_libs/index.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas/_libs/index.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'lon_band'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m test_bands \u001B[38;5;241m=\u001B[39m bands[test_index]\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Seleziona i punti corrispondenti alle bande\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m df_train \u001B[38;5;241m=\u001B[39m df_simulated_Holocene_2[df_simulated_Holocene_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlon_band\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39misin(train_bands)]\n\u001B[0;32m     37\u001B[0m df_test \u001B[38;5;241m=\u001B[39m df_simulated_Holocene_2[df_simulated_Holocene_2[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlon_band\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39misin(test_bands)]\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain bands: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_bands\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4107\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   4108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4109\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3815\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3816\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3817\u001B[0m     ):\n\u001B[0;32m   3818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3819\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3820\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3821\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3822\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3823\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'lon_band'"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
